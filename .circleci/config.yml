version: 2.1
# Use a package of configuration called an orb.
orbs:
  # Choose either one of the orbs below
  # welcome: circleci/welcome-orb@0.4.1
  aws-cli: circleci/aws-cli@2.0.3

# commands:
#   destroy_environment:
#     steps:
#       - run:
#           name: Destroy environment
#           # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
#           # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
#           when: on_fail
#           command: |
#             aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}
#   # Define the jobs we want to run for this project
jobs:
#   create_infrastructure: 
#     docker:
#       - image: amazon/aws-cli
#     steps:
#       - checkout
#       - run:
#           name: Create Cloudformation Stack
#           command: |
#             aws cloudformation deploy \
#               --template-file template.yml \
#               --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
#               --region us-east-1
#       # Fail the job intentionally to simulate an error.
#       # Uncomment the line below if you want to fail the current step
#       - run: return 1
#       - destroy_environment

#   # Exercise: Config and Deployment
#   # configure_infrastructure: 
#   #   docker:
#   #     - image: python:3.7-alpine3.11
#   #   steps:
#   #     - checkout
#   #     - add_ssh_keys:
#   #             # You can get this ID in the section where you registered the SSH Key
#   #             fingerprints: ["ef:86:fc:d3:9c:7d:ec:aa:5c:a5:17:ae:fd:f0:8e:59"] 
#   #     - run:
#   #         name: Install Ansible
#   #         command: |
#   #           # Install Ansible
#   #           apk add --update ansible
#   #     - run:
#   #         name: Run Playbook and Configure server
#   #         command: |
#   #           ansible-playbook -i inventory main-remote.yml


# # Exercise: Smoke Testing
#   smoke_test:
#     docker:
#       - image: alpine:latest
#     steps:
#       - run:
#           name: smoke test
#           command: |
#             return 1
#       - destroy_environment

# Job 1
  # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      # - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete

# Exercise: Promote to Production - Job 2
  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt 
  
  # Exercise: Promote to Production - Job 3
  # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
  # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}" 
  # Exercise: Promote to Production - Job 4
  # Destroy the previous production version's S3 bucket and CloudFormation stack. 
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous production version's S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive
          #  aws cloudformation delete-stack --stack-name production-distro 
          #  aws cloudformation delete-stack --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7}
          #  aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}



# Sequential workflow
workflows:
  # Name the workflow
  myWorkflow:
    jobs:
    #   - create_infrastructure
    # #  - configure_infrastructure
    #   - smoke_test
      
      - create_and_deploy_front_end
      - promote_to_production:
          requires: 
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
